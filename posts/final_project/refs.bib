@inproceedings{badshah2017speech,
  title={Speech emotion recognition from spectrograms with deep convolutional neural network},
  author={Badshah, Abdul Malik and Ahmad, Jamil and Rahim, Nasir and Baik, Sung Wook},
  booktitle={2017 international conference on platform technology and service (PlatCon)},
  pages={1--5},
  year={2017},
  organization={IEEE}
}

@inproceedings{xu2020improve,
  title={Improve accuracy of speech emotion recognition with attention head fusion},
  author={Xu, Mingke and Zhang, Fan and Khan, Samee U},
  booktitle={2020 10th annual computing and communication workshop and conference (CCWC)},
  pages={1058--1064},
  year={2020},
  organization={IEEE}
}

@inproceedings{kumbhar2019speech,
  title={Speech emotion recognition using MFCC features and LSTM network},
  author={Kumbhar, Harshawardhan S and Bhandari, Sheetal U},
  booktitle={2019 5th International Conference On Computing, Communication, Control And Automation (ICCUBEA)},
  pages={1--3},
  year={2019},
  organization={IEEE}
}

@article{livingstone2018ryerson,
  title={The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},
  author={Livingstone, Steven R and Russo, Frank A},
  journal={PloS one},
  volume={13},
  number={5},
  pages={e0196391},
  year={2018},
  publisher={Public Library of Science}
}

@article{hasan2021many,
  title={How many Mel-frequency cepstral coefficients to be utilized in speech recognition? A study with the Bengali language},
  author={Hasan, Md Rakibul and Hasan, Md Mahbub and Hossain, Md Zakir},
  journal={The Journal of Engineering},
  volume={2021},
  number={12},
  pages={817--827},
  year={2021},
  publisher={Wiley Online Library}
}